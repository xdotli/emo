<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3D%26id_list%3D2305.19184v1%26start%3D0%26max_results%3D1" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=&amp;id_list=2305.19184v1&amp;start=0&amp;max_results=1</title>
  <id>http://arxiv.org/api/+noAlWAPu2QMD/SgaUUt5eIcy6Y</id>
  <updated>2025-02-25T00:00:00-05:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">1</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">1</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2305.19184v1</id>
    <updated>2023-05-30T16:29:33Z</updated>
    <published>2023-05-30T16:29:33Z</published>
    <title>Leveraging Semantic Information for Efficient Self-Supervised Emotion
  Recognition with Audio-Textual Distilled Models</title>
    <summary>  In large part due to their implicit semantic modeling, self-supervised
learning (SSL) methods have significantly increased the performance of valence
recognition in speech emotion recognition (SER) systems. Yet, their large size
may often hinder practical implementations. In this work, we take HuBERT as an
example of an SSL model and analyze the relevance of each of its layers for
SER. We show that shallow layers are more important for arousal recognition
while deeper layers are more important for valence. This observation motivates
the importance of additional textual information for accurate valence
recognition, as the distilled framework lacks the depth of its large-scale SSL
teacher. Thus, we propose an audio-textual distilled SSL framework that, while
having only ~20% of the trainable parameters of a large SSL model, achieves on
par performance across the three emotion dimensions (arousal, valence,
dominance) on the MSP-Podcast v1.10 dataset.
</summary>
    <author>
      <name>Danilo de Oliveira</name>
    </author>
    <author>
      <name>Navin Raj Prabhu</name>
    </author>
    <author>
      <name>Timo Gerkmann</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.21437/Interspeech.2023-1758</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.21437/Interspeech.2023-1758" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at Interspeech 2023</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. Interspeech 2023</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2305.19184v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2305.19184v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
